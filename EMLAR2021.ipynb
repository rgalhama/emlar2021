{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributional Semantic Models in Python\n",
    "EMLAR, 2021\n",
    "\n",
    "TODO write some intro to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we import some libraries that will be useful\n",
    "import nltk #Natural Language Toolkit\n",
    "import numpy as np\n",
    "import pandas as pd # For data frames \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from collections\n",
    "import pattern\n",
    "from pattern.en import lemma\n",
    "#nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Change data? \n",
    "e.g.\n",
    "https://www.gutenberg.org/ebooks/bookshelves/search/?query=children|christmas|child|school\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from book that we have previously downloaded from Gutenberg project\n",
    "raw = open(\"pg6328.txt\", 'r').read()\n",
    "\n",
    "#Let's have a look at the data\n",
    "print(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data is a complete text. We need it separated by sentences and words.\n",
    "#This process is called \"tokenization\".\n",
    "#First we need to download a tokenizer from NLTK: ##maybe change to spacy and do everything with spacy?\n",
    "#nltk.download('punkt')\n",
    "\n",
    "#Now let's tokenize each sentence.\n",
    "#nltk.sent_tokenize gives us a method to do so\n",
    "sentences = nltk.sent_tokenize(raw)\n",
    "\n",
    "#And we tokenize all the words in each sentence and collect them together \n",
    "tokenized = []\n",
    "header=True\n",
    "for sentence in sentences:\n",
    "    if header and sentence.startswith(\"CONTENTS\"):\n",
    "        header = False\n",
    "    if not header: #We ignore everything before the table of contents\n",
    "        tokenized.append(nltk.wordpunct_tokenize(sentence))\n",
    "    \n",
    "\n",
    "#Let's look at the words. Do you spot any problem? (need to lemmatize and lowercase)\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase and lemmatize\n",
    "# TO DO!!! (nltk or spacy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's inspect our data (here we could do a bunch of stuff, not sure if necessary)\n",
    "\n",
    "#We first build a dictionary with word types and their frequencies\n",
    "word_frequencies = {}\n",
    "for sentence in tokenized:\n",
    "    for word in sentence:\n",
    "        word_frequencies[word] = word_frequencies.get(word,0) + 1\n",
    "\n",
    "\n",
    "#We first look at some of the most frequent words.\n",
    "# We construct a list of words ordered from most frequent to most infrequent\n",
    "sorted_keys = sorted(word_frequencies, key=word_frequencies.get, reverse=True)\n",
    "print(\"These are the 10 most frequent words: \", sorted_keys[:10])\n",
    "#todo decide whether to remove the stop words?\n",
    "\n",
    "\n",
    "#Not sure this is interesting:\n",
    "#Let's look at the singletons (i.e. words with frequency 1)\n",
    "singletons=[]\n",
    "for word, frequency in word_frequencies.items():\n",
    "    if frequency == 1:\n",
    "        singletons.append(word)\n",
    "print(\"We have {} singletons.\".format(len(singletons)))\n",
    "\n",
    "#TO DO Look at frequency distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is generally better to restrict models to words with a minimum frequency.\n",
    "# We define a minimum frequency threshold of 10 and filter the words:\n",
    "minfreq=10\n",
    "target_freqs = dict([(word,freq) for word,freq in word_frequencies.items() if freq>minfreq])\n",
    "#Here we have a list of all the words (targets) for our model:\n",
    "targets = target_freqs.keys()\n",
    "vocabulary_size=len(target_freqs)\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We associate a numerical index to each word, which we later use to locate the word in the co-occurrence matrix\n",
    "w2i = {w: i for i, w in enumerate(targets)}\n",
    "i2w = {i: w for i, w in enumerate(targets)}\n",
    "\n",
    "#Example:\n",
    "print(\"The code for the word \\\"cave\\\" is {}\".format(w2i[\"cave\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to build the co-occurrence matrix\n",
    "def calculate_cooccurrences(tokenized, vocabulary_size, window):\n",
    "    matrix = np.zeros([vocabulary_size,vocabulary_size]) \n",
    "    for sentence in tokenized:\n",
    "        for position,word in enumerate(sentence):                \n",
    "            for j in range(max(position-window,0),min(position+window+1,len(sentence))):\n",
    "                context=sentence[j]\n",
    "                if j!=position and word in targets and context in targets: \n",
    "                    matrix[w2i[word]][w2i[context]]+=1\n",
    "    return matrix\n",
    "\n",
    "\n",
    "#This function will give us the co-occurrence between two words\n",
    "def get_cooccurrence(word1, word2):\n",
    "    return co_occurrence_counts[w2i[word1]][w2i[word2]]\n",
    "\n",
    "#We now compute the co-occurrences in our tokenized text\n",
    "co_occurrence_counts=calculate_cooccurrences(tokenized, vocabulary_size, 2)\n",
    "\n",
    "#Let's have a look at some co-occurrences:\n",
    "print(get_cooccurrence(\"travelled\", \"distance\"))\n",
    "print(get_cooccurrence(\"next\", \"morning\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to do: if we apply (P)PMI, SVD, etc this would be the place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = cosine_similarity(co_occurrence_counts)\n",
    "print(similarities)\n",
    "\n",
    "#This function will give us the co-occurrence between two words\n",
    "def get_similarities(word1, word2):\n",
    "    return similarities[w2i[word1]][w2i[word2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_similarities(\"eat\", \"drink\"))\n",
    "print(get_similarities(\"lamp\",\"door\"))\n",
    "print(get_similarities(\"lamp\",\"drink\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From here we can do any tipe of analyses \n",
    "#(e.g. correlate with similarity judgements, find closest neighbours to one word, compare similarities between two different books, or sth like that)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHILDES DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thomas whats the matter whats the matter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>would you like some more juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oh that was a nice squeal thomas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wasnt it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wow juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>thomas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it has just gone eight oclock on wednesday mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>whose shoe is it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>its breakfast time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>what is it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           utterance\n",
       "0           thomas whats the matter whats the matter\n",
       "1                     would you like some more juice\n",
       "2                   oh that was a nice squeal thomas\n",
       "3                                           wasnt it\n",
       "4                                          wow juice\n",
       "5                                             thomas\n",
       "6  it has just gone eight oclock on wednesday mor...\n",
       "7                                   whose shoe is it\n",
       "8                                 its breakfast time\n",
       "9                                         what is it"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thomas = pd.read_csv('thomas.csv')\n",
    "thomas.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thomas whats the matter whats the matter</td>\n",
       "      <td>[thomas, whats, the, matter, whats, the, matter]</td>\n",
       "      <td>[thoma, what, the, matter, what, the, matter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>would you like some more juice</td>\n",
       "      <td>[would, you, like, some, more, juice]</td>\n",
       "      <td>[would, you, like, some, more, juice]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oh that was a nice squeal thomas</td>\n",
       "      <td>[oh, that, was, a, nice, squeal, thomas]</td>\n",
       "      <td>[oh, that, be, a, nice, squeal, thoma]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wasnt it</td>\n",
       "      <td>[wasnt, it]</td>\n",
       "      <td>[wasnt, it]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wow juice</td>\n",
       "      <td>[wow, juice]</td>\n",
       "      <td>[wow, juice]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>thomas</td>\n",
       "      <td>[thomas]</td>\n",
       "      <td>[thoma]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it has just gone eight oclock on wednesday mor...</td>\n",
       "      <td>[it, has, just, gone, eight, oclock, on, wedne...</td>\n",
       "      <td>[it, have, just, go, eight, oclock, on, wednes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>whose shoe is it</td>\n",
       "      <td>[whose, shoe, is, it]</td>\n",
       "      <td>[whose, shoe, be, it]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>its breakfast time</td>\n",
       "      <td>[its, breakfast, time]</td>\n",
       "      <td>[it, breakfast, time]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>what is it</td>\n",
       "      <td>[what, is, it]</td>\n",
       "      <td>[what, be, it]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           utterance  \\\n",
       "0           thomas whats the matter whats the matter   \n",
       "1                     would you like some more juice   \n",
       "2                   oh that was a nice squeal thomas   \n",
       "3                                           wasnt it   \n",
       "4                                          wow juice   \n",
       "5                                             thomas   \n",
       "6  it has just gone eight oclock on wednesday mor...   \n",
       "7                                   whose shoe is it   \n",
       "8                                 its breakfast time   \n",
       "9                                         what is it   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0   [thomas, whats, the, matter, whats, the, matter]   \n",
       "1              [would, you, like, some, more, juice]   \n",
       "2           [oh, that, was, a, nice, squeal, thomas]   \n",
       "3                                        [wasnt, it]   \n",
       "4                                       [wow, juice]   \n",
       "5                                           [thomas]   \n",
       "6  [it, has, just, gone, eight, oclock, on, wedne...   \n",
       "7                              [whose, shoe, is, it]   \n",
       "8                             [its, breakfast, time]   \n",
       "9                                     [what, is, it]   \n",
       "\n",
       "                                          lemmatized  \n",
       "0      [thoma, what, the, matter, what, the, matter]  \n",
       "1              [would, you, like, some, more, juice]  \n",
       "2             [oh, that, be, a, nice, squeal, thoma]  \n",
       "3                                        [wasnt, it]  \n",
       "4                                       [wow, juice]  \n",
       "5                                            [thoma]  \n",
       "6  [it, have, just, go, eight, oclock, on, wednes...  \n",
       "7                              [whose, shoe, be, it]  \n",
       "8                              [it, breakfast, time]  \n",
       "9                                     [what, be, it]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's tokenize each sentence\n",
    "tokenized = []\n",
    "for utterance in thomas['utterance']:\n",
    "     tokenized.append(nltk.wordpunct_tokenize(utterance))\n",
    "        \n",
    "# Add the tokenized list to the data frame\n",
    "thomas['tokenized'] = tokenized\n",
    "thomas.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thomas whats the matter whats the matter</td>\n",
       "      <td>[thomas, whats, the, matter, whats, the, matter]</td>\n",
       "      <td>[thoma, what, the, matter, what, the, matter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>would you like some more juice</td>\n",
       "      <td>[would, you, like, some, more, juice]</td>\n",
       "      <td>[would, you, like, some, more, juice]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oh that was a nice squeal thomas</td>\n",
       "      <td>[oh, that, was, a, nice, squeal, thomas]</td>\n",
       "      <td>[oh, that, be, a, nice, squeal, thoma]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wasnt it</td>\n",
       "      <td>[wasnt, it]</td>\n",
       "      <td>[wasnt, it]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wow juice</td>\n",
       "      <td>[wow, juice]</td>\n",
       "      <td>[wow, juice]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>thomas</td>\n",
       "      <td>[thomas]</td>\n",
       "      <td>[thoma]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it has just gone eight oclock on wednesday mor...</td>\n",
       "      <td>[it, has, just, gone, eight, oclock, on, wedne...</td>\n",
       "      <td>[it, have, just, go, eight, oclock, on, wednes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>whose shoe is it</td>\n",
       "      <td>[whose, shoe, is, it]</td>\n",
       "      <td>[whose, shoe, be, it]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>its breakfast time</td>\n",
       "      <td>[its, breakfast, time]</td>\n",
       "      <td>[it, breakfast, time]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>what is it</td>\n",
       "      <td>[what, is, it]</td>\n",
       "      <td>[what, be, it]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           utterance  \\\n",
       "0           thomas whats the matter whats the matter   \n",
       "1                     would you like some more juice   \n",
       "2                   oh that was a nice squeal thomas   \n",
       "3                                           wasnt it   \n",
       "4                                          wow juice   \n",
       "5                                             thomas   \n",
       "6  it has just gone eight oclock on wednesday mor...   \n",
       "7                                   whose shoe is it   \n",
       "8                                 its breakfast time   \n",
       "9                                         what is it   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0   [thomas, whats, the, matter, whats, the, matter]   \n",
       "1              [would, you, like, some, more, juice]   \n",
       "2           [oh, that, was, a, nice, squeal, thomas]   \n",
       "3                                        [wasnt, it]   \n",
       "4                                       [wow, juice]   \n",
       "5                                           [thomas]   \n",
       "6  [it, has, just, gone, eight, oclock, on, wedne...   \n",
       "7                              [whose, shoe, is, it]   \n",
       "8                             [its, breakfast, time]   \n",
       "9                                     [what, is, it]   \n",
       "\n",
       "                                          lemmatized  \n",
       "0      [thoma, what, the, matter, what, the, matter]  \n",
       "1              [would, you, like, some, more, juice]  \n",
       "2             [oh, that, be, a, nice, squeal, thoma]  \n",
       "3                                        [wasnt, it]  \n",
       "4                                       [wow, juice]  \n",
       "5                                            [thoma]  \n",
       "6  [it, have, just, go, eight, oclock, on, wednes...  \n",
       "7                              [whose, shoe, be, it]  \n",
       "8                              [it, breakfast, time]  \n",
       "9                                     [what, be, it]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized = []\n",
    "for utt in range(len(thomas['utterance'])):\n",
    "    utterance = []\n",
    "    for word in range(len(thomas.loc[utt, 'tokenized'])):\n",
    "        utterance.append(lemma(thomas.loc[utt, 'tokenized'][word]))\n",
    "    lemmatized.append(utterance)\n",
    "    \n",
    "# Add the tokenized list to the data frame\n",
    "thomas['lemmatized'] = lemmatized\n",
    "thomas.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "lemma_list = list(chain.from_iterable(thomas['lemmatized']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('you', 72546),\n",
       " ('the', 70985),\n",
       " ('be', 57763),\n",
       " ('it', 55045),\n",
       " ('a', 51713),\n",
       " ('and', 46044),\n",
       " ('that', 37012),\n",
       " ('to', 29431),\n",
       " ('have', 26805),\n",
       " ('i', 26198),\n",
       " ('do', 25902),\n",
       " ('we', 22783),\n",
       " ('what', 20808),\n",
       " ('go', 20189),\n",
       " ('on', 19683),\n",
       " ('oh', 19481),\n",
       " ('in', 19135),\n",
       " ('get', 16988),\n",
       " ('no', 15717),\n",
       " ('there', 15628)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = collections.Counter(lemma_list)\n",
    "freq.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequencies = {}\n",
    "for sentence in thomas['lemmatized']:\n",
    "    for word in sentence:\n",
    "        word_frequencies[word] = word_frequencies.get(word,0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the 10 most frequent words:  ['you', 'the', 'be', 'it', 'a', 'and', 'that', 'to', 'have', 'i']\n"
     ]
    }
   ],
   "source": [
    "sorted_keys = sorted(word_frequencies, key=word_frequencies.get, reverse=True)\n",
    "print(\"These are the 10 most frequent words: \", sorted_keys[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'thoma': 14307,\n",
       " 'what': 20808,\n",
       " 'the': 70985,\n",
       " 'matter': 664,\n",
       " 'would': 5144,\n",
       " 'you': 72546,\n",
       " 'like': 11822,\n",
       " 'some': 8215,\n",
       " 'more': 3168,\n",
       " 'juice': 1301,\n",
       " 'oh': 19481,\n",
       " 'that': 37012,\n",
       " 'be': 57763,\n",
       " 'a': 51713,\n",
       " 'nice': 5210,\n",
       " 'squeal': 51,\n",
       " 'wasnt': 1628,\n",
       " 'it': 55045,\n",
       " 'wow': 404,\n",
       " 'have': 26805,\n",
       " 'just': 9285,\n",
       " 'go': 20189,\n",
       " 'eight': 388,\n",
       " 'oclock': 419,\n",
       " 'on': 19683,\n",
       " 'wednesday': 178,\n",
       " 'morn': 1605,\n",
       " 'whose': 106,\n",
       " 'shoe': 747,\n",
       " 'breakfast': 765,\n",
       " 'time': 2429,\n",
       " 'bottle': 294,\n",
       " 'of': 15165,\n",
       " 'daddy': 3398,\n",
       " 'where': 3940,\n",
       " 'thomas': 330,\n",
       " 'orange': 1224,\n",
       " 'alright': 1357,\n",
       " 'let': 3594,\n",
       " 'put': 6804,\n",
       " 'your': 13208,\n",
       " 'and': 46044,\n",
       " 'sock': 357,\n",
       " 'come': 7088,\n",
       " 'sweetheart': 467,\n",
       " 'mummy': 6803,\n",
       " 'pour': 286,\n",
       " 'drop': 896,\n",
       " 'water': 1627,\n",
       " 'in': 19135,\n",
       " 'to': 29431,\n",
       " 'down': 4048,\n",
       " 'noise': 1095,\n",
       " 'background': 18,\n",
       " 'kettle': 75,\n",
       " 'boil': 84,\n",
       " 'so': 6081,\n",
       " 'can': 11663,\n",
       " 'make': 3594,\n",
       " 'herself': 82,\n",
       " 'cup': 801,\n",
       " 'tea': 1360,\n",
       " 'these': 2652,\n",
       " 'those': 2357,\n",
       " 'ill': 2600,\n",
       " 'get': 16988,\n",
       " 'do': 25902,\n",
       " 'say': 9296,\n",
       " 'please': 3633,\n",
       " 'need': 1707,\n",
       " 'clean': 690,\n",
       " 'because': 8016,\n",
       " 'we': 22783,\n",
       " 'out': 5036,\n",
       " 'thi': 11222,\n",
       " 'afternoon': 412,\n",
       " 'thank': 2127,\n",
       " 'drink': 1526,\n",
       " 'she': 6942,\n",
       " 'blue': 2165,\n",
       " 'bus': 1445,\n",
       " 'ah': 1382,\n",
       " 'i': 26198,\n",
       " 'see': 9284,\n",
       " 'ye': 11316,\n",
       " 'over': 1632,\n",
       " 'there': 15628,\n",
       " 'balloon': 393,\n",
       " 'right': 9697,\n",
       " 'how': 2185,\n",
       " 'many': 692,\n",
       " 'baby': 1188,\n",
       " 'trouser': 334,\n",
       " 'two': 3649,\n",
       " 'theyre': 3093,\n",
       " 'my': 2584,\n",
       " 'count': 283,\n",
       " 'four': 1005,\n",
       " 'thomasthetankengine': 349,\n",
       " 'one': 10635,\n",
       " 'three': 1557,\n",
       " 'who': 2804,\n",
       " 'po': 874,\n",
       " 'duck': 395,\n",
       " 'dipsy': 430,\n",
       " 'slipper': 266,\n",
       " 'arent': 3003,\n",
       " 'they': 8611,\n",
       " 'coach': 70,\n",
       " 'with': 9512,\n",
       " 'front': 507,\n",
       " 'call': 2455,\n",
       " 'look': 11701,\n",
       " 'at': 8152,\n",
       " 'hi': 2881,\n",
       " 'book': 1468,\n",
       " 'now': 10156,\n",
       " 'annie': 26,\n",
       " 'clarabel': 21,\n",
       " 'shall': 2733,\n",
       " 'which': 1179,\n",
       " 'lala': 420,\n",
       " 'know': 5062,\n",
       " 'glass': 367,\n",
       " 'milk': 912,\n",
       " 'biscuit': 720,\n",
       " 'nana': 540,\n",
       " 'jame': 274,\n",
       " 'dont': 12685,\n",
       " 'think': 11887,\n",
       " 'will': 2131,\n",
       " 'very': 6272,\n",
       " 'if': 5587,\n",
       " 'tinkywinky': 260,\n",
       " 'bread': 789,\n",
       " 'red': 2176,\n",
       " 'bertie': 85,\n",
       " 'perhap': 839,\n",
       " 'when': 7273,\n",
       " 'sh': 1738,\n",
       " 'wear': 847,\n",
       " 'her': 3882,\n",
       " 'coat': 244,\n",
       " 'banana': 358,\n",
       " 'aah': 224,\n",
       " 'beep': 289,\n",
       " 'pear': 435,\n",
       " 'good': 3010,\n",
       " 'boy': 2615,\n",
       " 'church': 230,\n",
       " 'corner': 137,\n",
       " 'show': 865,\n",
       " 'me': 5079,\n",
       " 'youve': 5605,\n",
       " 'shop': 1918,\n",
       " 'basket': 283,\n",
       " 'fruit': 470,\n",
       " 'havent': 2912,\n",
       " 'ricekrispy': 136,\n",
       " 'toby': 57,\n",
       " 'no': 15717,\n",
       " 'engine': 1186,\n",
       " 'not': 9295,\n",
       " 'percy': 124,\n",
       " 'football': 252,\n",
       " 'well': 13851,\n",
       " 'grape': 448,\n",
       " 'cucumber': 55,\n",
       " 'isnt': 5940,\n",
       " 'place': 324,\n",
       " 'for': 7672,\n",
       " 'lettuce': 21,\n",
       " 'about': 3944,\n",
       " 'only': 1198,\n",
       " 'quiet': 286,\n",
       " 'weve': 4395,\n",
       " 'youre': 8944,\n",
       " 'asleep': 217,\n",
       " 'here': 3640,\n",
       " 'he': 12070,\n",
       " 'an': 2348,\n",
       " 'byebye': 131,\n",
       " 'dress': 440,\n",
       " 'ball': 332,\n",
       " 'green': 1721,\n",
       " 'wash': 1612,\n",
       " 'outside': 1297,\n",
       " 'face': 620,\n",
       " 'hand': 1634,\n",
       " 'postman': 418,\n",
       " 'sleep': 964,\n",
       " 'apple': 1263,\n",
       " 'tire': 648,\n",
       " 'brush': 792,\n",
       " 'teeth': 404,\n",
       " 'van': 609,\n",
       " 'parcel': 236,\n",
       " 'snore': 47,\n",
       " 'cant': 3518,\n",
       " 'yet': 570,\n",
       " 'after': 840,\n",
       " 'knock': 283,\n",
       " 'someone': 66,\n",
       " 'door': 1470,\n",
       " 'marmite': 87,\n",
       " 'from': 3036,\n",
       " 'toast': 761,\n",
       " 'all': 6984,\n",
       " 'around': 557,\n",
       " 'mouth': 547,\n",
       " 'darle': 1192,\n",
       " 'another': 1731,\n",
       " 'bump': 387,\n",
       " 'toe': 218,\n",
       " 'easier': 66,\n",
       " 'chair': 1341,\n",
       " 'choochoo': 155,\n",
       " 'dear': 2853,\n",
       " 'yeah': 843,\n",
       " 'kiss': 677,\n",
       " 'ooh': 521,\n",
       " 'too': 1615,\n",
       " 'heavy': 199,\n",
       " 'big': 4339,\n",
       " 'better': 1253,\n",
       " 'today': 1610,\n",
       " 'somebody': 901,\n",
       " 'else': 1266,\n",
       " 'pen': 118,\n",
       " 'write': 444,\n",
       " 'somethe': 2157,\n",
       " 'try': 1146,\n",
       " 'find': 1294,\n",
       " 'deliver': 265,\n",
       " 'postmanpat': 764,\n",
       " 'but': 7718,\n",
       " 'hasnt': 1027,\n",
       " 'black': 467,\n",
       " 'white': 1014,\n",
       " 'cat': 1464,\n",
       " 'home': 1226,\n",
       " 'usually': 514,\n",
       " 'yesterday': 605,\n",
       " 'floor': 1351,\n",
       " 'our': 870,\n",
       " 'tabby': 39,\n",
       " 'new': 746,\n",
       " 'peeppeep': 13,\n",
       " 'pick': 853,\n",
       " 'up': 6661,\n",
       " 'bit': 3124,\n",
       " 'lemon': 124,\n",
       " 'poor': 527,\n",
       " 'anybody': 207,\n",
       " 'beg': 58,\n",
       " 'pardon': 1281,\n",
       " 'hear': 1387,\n",
       " 'color': 932,\n",
       " 'chocchoc': 147,\n",
       " 'last': 1116,\n",
       " 'night': 1029,\n",
       " 'nobody': 144,\n",
       " 'jake': 146,\n",
       " 'party': 590,\n",
       " 'old': 550,\n",
       " 'yellow': 1467,\n",
       " 'hair': 639,\n",
       " 'mess': 726,\n",
       " 'doesnt': 2672,\n",
       " 'mean': 1709,\n",
       " 'hafta': 1655,\n",
       " 'throw': 936,\n",
       " 'stick': 916,\n",
       " 'week': 782,\n",
       " 'bowl': 693,\n",
       " 'pea': 202,\n",
       " 'car': 2212,\n",
       " 'paper': 710,\n",
       " 'box': 2274,\n",
       " 'listen': 854,\n",
       " 'quickly': 405,\n",
       " 'saturday': 243,\n",
       " 'crackle': 70,\n",
       " 'man': 1901,\n",
       " 'wet': 482,\n",
       " 'shower': 81,\n",
       " 'talk': 1520,\n",
       " 'him': 1685,\n",
       " 'nosy': 11,\n",
       " 'neighbor': 65,\n",
       " 'then': 5389,\n",
       " 'u': 769,\n",
       " 'packet': 349,\n",
       " 'dry': 414,\n",
       " 'before': 1396,\n",
       " 'tomato': 70,\n",
       " 'watch': 1533,\n",
       " 'roll': 670,\n",
       " 'round': 2217,\n",
       " 'snap': 137,\n",
       " 'drive': 813,\n",
       " 'off': 2884,\n",
       " 'few': 684,\n",
       " 'minute': 1058,\n",
       " 'pop': 968,\n",
       " 'shirt': 178,\n",
       " 'remember': 2039,\n",
       " 'head': 1053,\n",
       " 'hat': 964,\n",
       " 'im': 4112,\n",
       " 'sure': 854,\n",
       " 'silly': 764,\n",
       " 'crush': 45,\n",
       " 'yoghurt': 192,\n",
       " 'pot': 691,\n",
       " 'little': 7128,\n",
       " 'shout': 330,\n",
       " 'ninnin': 229,\n",
       " 'pbbear': 66,\n",
       " 'back': 3902,\n",
       " 'wave': 400,\n",
       " 'choose': 147,\n",
       " 'warm': 370,\n",
       " 'cheeky': 439,\n",
       " 'should': 762,\n",
       " 'sit': 2880,\n",
       " 'highchair': 109,\n",
       " 'first': 802,\n",
       " 'help': 988,\n",
       " 'tie': 75,\n",
       " 'wodar': 29,\n",
       " 'start': 968,\n",
       " 'day': 1970,\n",
       " 'scarf': 60,\n",
       " 'brown': 442,\n",
       " 'ready': 604,\n",
       " 'play': 2380,\n",
       " 'bring': 832,\n",
       " 'photograph': 127,\n",
       " 'them': 5680,\n",
       " 'woolly': 27,\n",
       " 'most': 177,\n",
       " 'together': 591,\n",
       " 'quite': 1883,\n",
       " 'bear': 893,\n",
       " 'strap': 167,\n",
       " 'into': 2151,\n",
       " 'seat': 112,\n",
       " 'waistcoat': 59,\n",
       " 'collect': 275,\n",
       " 'couldnt': 693,\n",
       " 'bib': 209,\n",
       " 'lace': 20,\n",
       " 'hold': 804,\n",
       " 'lastname': 284,\n",
       " 'giddy': 65,\n",
       " 'oop': 752,\n",
       " 'abigail': 110,\n",
       " 'rather': 211,\n",
       " 'than': 692,\n",
       " 'mud': 67,\n",
       " 'dirty': 499,\n",
       " 'tiny': 318,\n",
       " 'hour': 188,\n",
       " 'ive': 2271,\n",
       " 'take': 2438,\n",
       " 'stand': 578,\n",
       " 'again': 2070,\n",
       " 'hello': 1028,\n",
       " 'once': 316,\n",
       " 'work': 1515,\n",
       " 'grandma': 1025,\n",
       " 'granddad': 854,\n",
       " 'weekend': 105,\n",
       " 'pair': 135,\n",
       " 'dimitra': 664,\n",
       " 'poohbear': 93,\n",
       " 'youll': 979,\n",
       " 'probably': 696,\n",
       " 'much': 1162,\n",
       " 'excite': 260,\n",
       " 'shell': 215,\n",
       " 'mind': 628,\n",
       " 'inside': 762,\n",
       " 'run': 896,\n",
       " 'straight': 283,\n",
       " 'upstair': 588,\n",
       " 'food': 859,\n",
       " 'thatll': 95,\n",
       " 'downstair': 123,\n",
       " 'or': 3479,\n",
       " 'fridge': 341,\n",
       " 'tin': 278,\n",
       " 'cupboard': 451,\n",
       " 'scruffy': 28,\n",
       " 'still': 1502,\n",
       " 'eat': 3375,\n",
       " 'chocolate': 1039,\n",
       " 'fall': 1575,\n",
       " 'tray': 205,\n",
       " 'happen': 1647,\n",
       " 'must': 1221,\n",
       " 'lunch': 776,\n",
       " 'full': 355,\n",
       " 'fruitbowl': 17,\n",
       " 'behind': 450,\n",
       " 'whoop': 129,\n",
       " 'read': 649,\n",
       " 'storybook': 19,\n",
       " 'gorgeou': 102,\n",
       " 'theyll': 275,\n",
       " 'johnlewi': 75,\n",
       " 'ride': 459,\n",
       " 'lift': 445,\n",
       " 'noahsark': 33,\n",
       " 'toy': 830,\n",
       " 'department': 12,\n",
       " 'restaurant': 51,\n",
       " 'smart': 148,\n",
       " 'coffee': 333,\n",
       " 'sun': 600,\n",
       " 'purdie': 2565,\n",
       " 'moon': 228,\n",
       " 'outfit': 44,\n",
       " 'haircut': 19,\n",
       " 'actually': 1412,\n",
       " 'cut': 900,\n",
       " 'stay': 501,\n",
       " 'beautiful': 522,\n",
       " 'hungry': 234,\n",
       " 'careful': 1266,\n",
       " 'wanna': 2045,\n",
       " 'six': 654,\n",
       " 'five': 706,\n",
       " 'lose': 295,\n",
       " 'might': 1708,\n",
       " 'twin': 40,\n",
       " 'pig': 306,\n",
       " 'ark': 13,\n",
       " 'pull': 651,\n",
       " 'didnt': 4988,\n",
       " 'feet': 404,\n",
       " 'bet': 325,\n",
       " 'purdy': 741,\n",
       " 'aeroplane': 240,\n",
       " 'jumper': 212,\n",
       " 'hang': 263,\n",
       " 'mr': 78,\n",
       " 'noah': 21,\n",
       " 'under': 495,\n",
       " 'cushion': 160,\n",
       " 'ear': 335,\n",
       " 'worry': 217,\n",
       " 'older': 68,\n",
       " 'rebecca': 15,\n",
       " 'christen': 44,\n",
       " 'earlier': 190,\n",
       " 'walk': 1213,\n",
       " 'near': 405,\n",
       " 'vicar': 14,\n",
       " 'becky': 227,\n",
       " 'why': 1925,\n",
       " 'give': 1982,\n",
       " 'open': 1245,\n",
       " 'everyone': 54,\n",
       " 'hide': 481,\n",
       " 'own': 392,\n",
       " 'want': 2948,\n",
       " 'lovely': 952,\n",
       " 'poorly': 408,\n",
       " 'suit': 76,\n",
       " 'other': 1914,\n",
       " 'animal': 244,\n",
       " 'bed': 780,\n",
       " 'friend': 414,\n",
       " 'teddybear': 101,\n",
       " 'putt': 951,\n",
       " 'toaster': 117,\n",
       " 'tinypig': 18,\n",
       " 'top': 929,\n",
       " 'cotton': 63,\n",
       " 'reel': 12,\n",
       " 'sofa': 134,\n",
       " 'shape': 398,\n",
       " 'bright': 220,\n",
       " 'birthday': 1002,\n",
       " 'either': 395,\n",
       " 'hippopotamu': 20,\n",
       " 'vest': 161,\n",
       " 'hot': 759,\n",
       " 'poppet': 155,\n",
       " 'itll': 543,\n",
       " 'burn': 128,\n",
       " 'stair': 181,\n",
       " 'sharp': 169,\n",
       " 'needle': 17,\n",
       " 'dad': 60,\n",
       " 'okay': 1308,\n",
       " 'bash': 97,\n",
       " 'spoon': 494,\n",
       " 'slide': 186,\n",
       " 'laugh': 217,\n",
       " 'mouthful': 48,\n",
       " 'finish': 1024,\n",
       " 'giraffe': 102,\n",
       " 'marmalade': 149,\n",
       " 'butter': 113,\n",
       " 'gentle': 185,\n",
       " 'toybox': 12,\n",
       " 'really': 2509,\n",
       " 'mm': 663,\n",
       " 'theyve': 838,\n",
       " 'stripe': 120,\n",
       " 'empty': 467,\n",
       " 'picture': 1074,\n",
       " 'sort': 1078,\n",
       " 'towel': 191,\n",
       " 'clothe': 283,\n",
       " 'lion': 175,\n",
       " 'belong': 214,\n",
       " 'machine': 485,\n",
       " 'climb': 315,\n",
       " 'eleven': 119,\n",
       " 'clear': 159,\n",
       " 'while': 779,\n",
       " 'left': 733,\n",
       " 'bottom': 528,\n",
       " 'spread': 91,\n",
       " 'blow': 637,\n",
       " 'bubble': 365,\n",
       " 'teddy': 724,\n",
       " 'horse': 456,\n",
       " 'naughty': 574,\n",
       " 'grass': 317,\n",
       " 'edward': 34,\n",
       " 'elephant': 404,\n",
       " 'cheese': 1043,\n",
       " 'sandwich': 517,\n",
       " 'dark': 382,\n",
       " 'sky': 276,\n",
       " 'dungaree': 19,\n",
       " 'ask': 667,\n",
       " 'tshirt': 164,\n",
       " 'sew': 14,\n",
       " 'onto': 358,\n",
       " 'nearly': 422,\n",
       " 'truck': 1360,\n",
       " 'vroom': 48,\n",
       " 'even': 535,\n",
       " 'airport': 105,\n",
       " 'catch': 348,\n",
       " 'colore': 156,\n",
       " 'plate': 543,\n",
       " 'button': 480,\n",
       " 'pooh': 57,\n",
       " 'wind': 182,\n",
       " 'winniethepooh': 167,\n",
       " 'lot': 1919,\n",
       " 'flower': 708,\n",
       " 'pile': 104,\n",
       " 'washingmachine': 22,\n",
       " 'seven': 417,\n",
       " 'slice': 185,\n",
       " 'ramp': 34,\n",
       " 'fur': 97,\n",
       " 'eye': 530,\n",
       " 'nose': 587,\n",
       " 'turn': 889,\n",
       " 'though': 756,\n",
       " 'later': 689,\n",
       " 'wont': 1613,\n",
       " 'properly': 225,\n",
       " 'instead': 234,\n",
       " 'candle': 236,\n",
       " 'meow': 156,\n",
       " 'patio': 115,\n",
       " 'wipe': 630,\n",
       " 'noisy': 189,\n",
       " 'knee': 425,\n",
       " 'sang': 108,\n",
       " 'happybirthday': 16,\n",
       " 'taste': 425,\n",
       " 'fan': 24,\n",
       " 'soft': 138,\n",
       " 'bow': 210,\n",
       " 'love': 872,\n",
       " 'jump': 529,\n",
       " 'april': 87,\n",
       " 'ribbon': 97,\n",
       " 'neck': 150,\n",
       " 'molly': 271,\n",
       " 'moment': 562,\n",
       " 'ago': 290,\n",
       " 'velvet': 13,\n",
       " 'touch': 629,\n",
       " 'share': 232,\n",
       " 'piece': 1457,\n",
       " 'frighten': 298,\n",
       " 'name': 476,\n",
       " 'through': 1229,\n",
       " 'handle': 126,\n",
       " 'bedroom': 212,\n",
       " 'scream': 56,\n",
       " 'point': 234,\n",
       " 'light': 1006,\n",
       " 'high': 287,\n",
       " 'hit': 259,\n",
       " 'boat': 197,\n",
       " 'tell': 2390,\n",
       " 'therere': 46,\n",
       " 'pink': 568,\n",
       " 'feed': 82,\n",
       " 'sound': 1053,\n",
       " 'hard': 367,\n",
       " 'longer': 77,\n",
       " 'bath': 519,\n",
       " 'enough': 572,\n",
       " 'lady': 669,\n",
       " 'sue': 634,\n",
       " 'bless': 80,\n",
       " 'wand': 23,\n",
       " 'leave': 1041,\n",
       " 'step': 346,\n",
       " 'spot': 169,\n",
       " 'copy': 37,\n",
       " 'dog': 572,\n",
       " 'bark': 96,\n",
       " 'maybe': 92,\n",
       " 'clearly': 14,\n",
       " 'pussy': 916,\n",
       " 'block': 78,\n",
       " 'view': 15,\n",
       " 'heart': 70,\n",
       " 'doggy': 79,\n",
       " 'meat': 30,\n",
       " 'crunchy': 130,\n",
       " 'sailor': 16,\n",
       " 'stripy': 70,\n",
       " 'wonderful': 129,\n",
       " 'middle': 179,\n",
       " 'their': 628,\n",
       " 'paddingtonbear': 29,\n",
       " 'toward': 108,\n",
       " 'clever': 478,\n",
       " 'rattle': 53,\n",
       " 'gosh': 329,\n",
       " 'otherwise': 273,\n",
       " 'loud': 135,\n",
       " 'shake': 194,\n",
       " 'gently': 393,\n",
       " 'shouldnt': 231,\n",
       " 'born': 46,\n",
       " 'way': 1074,\n",
       " 'cot': 52,\n",
       " 'until': 289,\n",
       " 'christma': 1000,\n",
       " 'tree': 1139,\n",
       " 'werent': 807,\n",
       " 'rough': 124,\n",
       " 'table': 1224,\n",
       " 'strawberry': 566,\n",
       " 'smell': 770,\n",
       " 'tape': 478,\n",
       " 'cool': 126,\n",
       " 'wiggly': 26,\n",
       " 'prop': 14,\n",
       " 'straw': 250,\n",
       " 'cloth': 239,\n",
       " 'sticky': 265,\n",
       " 'needta': 880,\n",
       " 'tonight': 211,\n",
       " 'without': 271,\n",
       " 'program': 114,\n",
       " 'pippin': 495,\n",
       " 'visit': 84,\n",
       " 'geese': 17,\n",
       " 'pussycat': 126,\n",
       " 'rug': 34,\n",
       " 'next': 932,\n",
       " 'windy': 90,\n",
       " 'soap': 152,\n",
       " 'whistle': 155,\n",
       " 'youd': 780,\n",
       " 'used': 537,\n",
       " 'paw': 110,\n",
       " 'meal': 247,\n",
       " 'peace': 32,\n",
       " 'both': 368,\n",
       " 'wall': 185,\n",
       " 'carry': 445,\n",
       " 'special': 366,\n",
       " 'far': 193,\n",
       " 'quack': 97,\n",
       " 'float': 60,\n",
       " 'past': 500,\n",
       " 'stop': 1054,\n",
       " 'beaker': 227,\n",
       " 'mug': 62,\n",
       " 'funny': 757,\n",
       " 'early': 177,\n",
       " 'pyjama': 98,\n",
       " 'saucer': 117,\n",
       " 'half': 312,\n",
       " 'puppy': 42,\n",
       " 'letter': 1060,\n",
       " 'window': 797,\n",
       " 'any': 1287,\n",
       " 'post': 941,\n",
       " 'hurt': 603,\n",
       " 'anythe': 731,\n",
       " 'pass': 154,\n",
       " 'hasta': 106,\n",
       " 'pant': 99,\n",
       " 'ring': 451,\n",
       " 'bell': 218,\n",
       " 'away': 1331,\n",
       " 'card': 798,\n",
       " 'thing': 3043,\n",
       " 'postbox': 129,\n",
       " 'stir': 111,\n",
       " 'alway': 665,\n",
       " 'nicer': 32,\n",
       " 'bird': 366,\n",
       " 'thirsty': 83,\n",
       " 'bare': 19,\n",
       " 'binbag': 33,\n",
       " 'people': 1057,\n",
       " 'house': 1710,\n",
       " 'monday': 287,\n",
       " 'dustbin': 754,\n",
       " 'rubbish': 476,\n",
       " 'bin': 853,\n",
       " 'dure': 54,\n",
       " 'bag': 1670,\n",
       " 'playgroup': 211,\n",
       " 'exactly': 94,\n",
       " 'same': 491,\n",
       " 'wheel': 509,\n",
       " 'wiper': 24,\n",
       " 'swishswishswish': 13,\n",
       " 'cornflake': 537,\n",
       " 'verse': 20,\n",
       " 'horn': 44,\n",
       " 'boo': 109,\n",
       " 'girl': 617,\n",
       " 'disappoint': 29,\n",
       " 'men': 573,\n",
       " 'side': 738,\n",
       " 'story': 653,\n",
       " 'mouse': 261,\n",
       " 'blossom': 27,\n",
       " 'ship': 62,\n",
       " 'dance': 154,\n",
       " 'jam': 385,\n",
       " 'train': 2630,\n",
       " 'snow': 341,\n",
       " 'mustnt': 380,\n",
       " 'yourself': 295,\n",
       " 'mention': 32,\n",
       " 'glove': 95,\n",
       " 'tigger': 120,\n",
       " 'cold': 523,\n",
       " 'cloudy': 15,\n",
       " 'keep': 1330,\n",
       " 'plum': 52,\n",
       " 'fly': 231,\n",
       " 'march': 164,\n",
       " 'lie': 533,\n",
       " 'kitchen': 367,\n",
       " 'cherry': 171,\n",
       " 'bathroom': 116,\n",
       " 'surprise': 168,\n",
       " 'pretty': 204,\n",
       " 'scooter': 83,\n",
       " 'break': 920,\n",
       " 'live': 484,\n",
       " 'road': 498,\n",
       " 'pansy': 21,\n",
       " 'goodnes': 238,\n",
       " 'lotsof': 881,\n",
       " 'third': 77,\n",
       " 'crunch': 160,\n",
       " 'rabbit': 315,\n",
       " 'magician': 11,\n",
       " 'linda': 265,\n",
       " 'alice': 91,\n",
       " 'woof': 77,\n",
       " 'piglet': 68,\n",
       " 'purple': 157,\n",
       " 'spill': 218,\n",
       " 'dobbin': 120,\n",
       " 'low': 51,\n",
       " 'noonoo': 130,\n",
       " 'mend': 136,\n",
       " 'teapot': 68,\n",
       " 'sing': 764,\n",
       " 'crumb': 171,\n",
       " 'busy': 542,\n",
       " 'sellotape': 61,\n",
       " 'poo': 185,\n",
       " 'snipsnip': 43,\n",
       " 'tickle': 179,\n",
       " 'scissor': 242,\n",
       " 'close': 395,\n",
       " 'scratch': 143,\n",
       " 'toenail': 17,\n",
       " 'push': 323,\n",
       " 'battery': 198,\n",
       " 'cough': 161,\n",
       " 'fish': 505,\n",
       " 'cuddle': 282,\n",
       " 'finger': 621,\n",
       " 'lick': 202,\n",
       " 'cake': 711,\n",
       " 'may': 212,\n",
       " 'telephone': 323,\n",
       " 'piggy': 116,\n",
       " 'print': 34,\n",
       " 'till': 256,\n",
       " 'tomorrow': 348,\n",
       " 'chew': 55,\n",
       " 'money': 653,\n",
       " 'feel': 928,\n",
       " 'pond': 108,\n",
       " 'quackquack': 16,\n",
       " 'notice': 163,\n",
       " 'tummy': 563,\n",
       " 'split': 11,\n",
       " 'absolutely': 175,\n",
       " 'nothe': 341,\n",
       " 'apart': 145,\n",
       " 'film': 42,\n",
       " 'undress': 19,\n",
       " 'sorry': 707,\n",
       " 'pretend': 511,\n",
       " 'garden': 615,\n",
       " 'unclebrian': 73,\n",
       " 'bang': 956,\n",
       " 'hammer': 102,\n",
       " 'melt': 99,\n",
       " 'badge': 107,\n",
       " 'year': 457,\n",
       " 'cook': 252,\n",
       " 'bandage': 35,\n",
       " 'arm': 309,\n",
       " 'oink': 41,\n",
       " 'egg': 478,\n",
       " 'fishes': 121,\n",
       " 'dandelion': 71,\n",
       " 'popper': 46,\n",
       " 'curtain': 87,\n",
       " 'zip': 53,\n",
       " 'snip': 151,\n",
       " 'never': 612,\n",
       " 'hell': 218,\n",
       " 'soon': 240,\n",
       " 'whatre': 129,\n",
       " 'frog': 108,\n",
       " 'peel': 191,\n",
       " 'small': 458,\n",
       " 'rest': 223,\n",
       " 'snack': 43,\n",
       " 'd': 150,\n",
       " 'cardigan': 33,\n",
       " 'tip': 420,\n",
       " 'buy': 1527,\n",
       " 'square': 87,\n",
       " 'bead': 117,\n",
       " 'sleeve': 97,\n",
       " 'reach': 236,\n",
       " 'clap': 111,\n",
       " 'whilst': 25,\n",
       " 'polish': 62,\n",
       " 'trailer': 235,\n",
       " 'jar': 201,\n",
       " 'backward': 177,\n",
       " 'oughta': 76,\n",
       " 'soak': 33,\n",
       " 'nine': 435,\n",
       " 'ten': 335,\n",
       " 'twelve': 177,\n",
       " 'thirteen': 46,\n",
       " 'fourteen': 39,\n",
       " 'fifteen': 46,\n",
       " 'sixteen': 71,\n",
       " 'seventeen': 47,\n",
       " 'eighteen': 35,\n",
       " 'nineteen': 55,\n",
       " 'twenty': 316,\n",
       " 'thirty': 103,\n",
       " 'windmill': 99,\n",
       " 'wooden': 242,\n",
       " 'microwave': 23,\n",
       " 'heat': 48,\n",
       " 'fit': 325,\n",
       " 'tractor': 346,\n",
       " 'mix': 273,\n",
       " 'oldmacdonald': 26,\n",
       " 'cab': 179,\n",
       " 'teletubby': 525,\n",
       " 'ahhah': 15,\n",
       " 'quick': 515,\n",
       " 'whale': 24,\n",
       " 'thick': 50,\n",
       " 'tight': 57,\n",
       " 'easter': 101,\n",
       " 'lid': 596,\n",
       " 'net': 69,\n",
       " 'number': 918,\n",
       " 'leg': 472,\n",
       " 'enjoy': 538,\n",
       " 'between': 118,\n",
       " 'hook': 86,\n",
       " 'chimney': 59,\n",
       " 'shut': 350,\n",
       " 'load': 140,\n",
       " 'ugh': 72,\n",
       " 'farmer': 120,\n",
       " 'eggbox': 22,\n",
       " 'dadda': 34,\n",
       " 'long': 1002,\n",
       " 'cover': 233,\n",
       " 'squeak': 80,\n",
       " 'itself': 21,\n",
       " 'crispy': 45,\n",
       " 'skirt': 54,\n",
       " 'cow': 134,\n",
       " 'sheep': 224,\n",
       " 'underneath': 206,\n",
       " 'younger': 34,\n",
       " 'job': 387,\n",
       " 'real': 200,\n",
       " 'scrape': 50,\n",
       " 'june': 40,\n",
       " 'allow': 88,\n",
       " 'everyday': 44,\n",
       " 'clip': 111,\n",
       " 'promise': 63,\n",
       " 'theyd': 91,\n",
       " 'smash': 138,\n",
       " 'fasten': 35,\n",
       " 'wouldnt': 865,\n",
       " 'farm': 164,\n",
       " 'by': 571,\n",
       " 'everythe': 323,\n",
       " 'treat': 135,\n",
       " 'case': 238,\n",
       " 'hedgehog': 60,\n",
       " 'wallpaper': 27,\n",
       " 'wallet': 11,\n",
       " 'fun': 178,\n",
       " 'playdoh': 139,\n",
       " 'afterward': 65,\n",
       " 'different': 580,\n",
       " 'type': 62,\n",
       " 'mine': 168,\n",
       " 'driver': 766,\n",
       " 'plain': 70,\n",
       " 'follow': 63,\n",
       " 'separate': 36,\n",
       " 'hole': 221,\n",
       " 'helmet': 245,\n",
       " 'bye': 1093,\n",
       " 'sneak': 11,\n",
       " 'use': 724,\n",
       " 'part': 176,\n",
       " 'wait': 559,\n",
       " 'digger': 604,\n",
       " 'press': 477,\n",
       " 'helicopter': 197,\n",
       " 'undo': 41,\n",
       " 'manage': 226,\n",
       " 'policeman': 283,\n",
       " 'police': 448,\n",
       " 'teaspoon': 59,\n",
       " 'breakdown': 95,\n",
       " 'prefer': 57,\n",
       " 'traffic': 141,\n",
       " 'cone': 160,\n",
       " 'sign': 243,\n",
       " 'ouch': 60,\n",
       " 'mini': 63,\n",
       " 'lunchtime': 142,\n",
       " 'music': 312,\n",
       " 'forget': 398,\n",
       " 'mixture': 62,\n",
       " 'rider': 34,\n",
       " 'sometime': 420,\n",
       " 'useta': 898,\n",
       " 'mum': 115,\n",
       " 'helpful': 36,\n",
       " 'fireguard': 21,\n",
       " 'huge': 121,\n",
       " 'build': 541,\n",
       " 'sposta': 242,\n",
       " 'turtle': 19,\n",
       " 'sweet': 749,\n",
       " 'friday': 290,\n",
       " 'pajama': 49,\n",
       " 'along': 440,\n",
       " ...}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We define a minimum frequency threshold of 10 and filter the words:\n",
    "minfreq = 10\n",
    "target_freqs = dict([(word,freq) for word,freq in word_frequencies.items() if freq>minfreq])\n",
    "#Here we have a list of all the words (targets) for our model:\n",
    "targets = target_freqs.keys()\n",
    "vocabulary_size=len(target_freqs)\n",
    "print(vocabulary_size)\n",
    "target_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['thoma', 'what', 'the', 'matter', 'would', 'you', 'like', 'some', 'more', 'juice', 'oh', 'that', 'be', 'a', 'nice', 'squeal', 'wasnt', 'it', 'wow', 'have', 'just', 'go', 'eight', 'oclock', 'on', 'wednesday', 'morn', 'whose', 'shoe', 'breakfast', 'time', 'bottle', 'of', 'daddy', 'where', 'thomas', 'orange', 'alright', 'let', 'put', 'your', 'and', 'sock', 'come', 'sweetheart', 'mummy', 'pour', 'drop', 'water', 'in', 'to', 'down', 'noise', 'background', 'kettle', 'boil', 'so', 'can', 'make', 'herself', 'cup', 'tea', 'these', 'those', 'ill', 'get', 'do', 'say', 'please', 'need', 'clean', 'because', 'we', 'out', 'thi', 'afternoon', 'thank', 'drink', 'she', 'blue', 'bus', 'ah', 'i', 'see', 'ye', 'over', 'there', 'balloon', 'right', 'how', 'many', 'baby', 'trouser', 'two', 'theyre', 'my', 'count', 'four', 'thomasthetankengine', 'one', 'three', 'who', 'po', 'duck', 'dipsy', 'slipper', 'arent', 'they', 'coach', 'with', 'front', 'call', 'look', 'at', 'hi', 'book', 'now', 'annie', 'clarabel', 'shall', 'which', 'lala', 'know', 'glass', 'milk', 'biscuit', 'nana', 'jame', 'dont', 'think', 'will', 'very', 'if', 'tinkywinky', 'bread', 'red', 'bertie', 'perhap', 'when', 'sh', 'wear', 'her', 'coat', 'banana', 'aah', 'beep', 'pear', 'good', 'boy', 'church', 'corner', 'show', 'me', 'youve', 'shop', 'basket', 'fruit', 'havent', 'ricekrispy', 'toby', 'no', 'engine', 'not', 'percy', 'football', 'well', 'grape', 'cucumber', 'isnt', 'place', 'for', 'lettuce', 'about', 'only', 'quiet', 'weve', 'youre', 'asleep', 'here', 'he', 'an', 'byebye', 'dress', 'ball', 'green', 'wash', 'outside', 'face', 'hand', 'postman', 'sleep', 'apple', 'tire', 'brush', 'teeth', 'van', 'parcel', 'snore', 'cant', 'yet', 'after', 'knock', 'someone', 'door', 'marmite', 'from', 'toast', 'all', 'around', 'mouth', 'darle', 'another', 'bump', 'toe', 'easier', 'chair', 'choochoo', 'dear', 'yeah', 'kiss', 'ooh', 'too', 'heavy', 'big', 'better', 'today', 'somebody', 'else', 'pen', 'write', 'somethe', 'try', 'find', 'deliver', 'postmanpat', 'but', 'hasnt', 'black', 'white', 'cat', 'home', 'usually', 'yesterday', 'floor', 'our', 'tabby', 'new', 'peeppeep', 'pick', 'up', 'bit', 'lemon', 'poor', 'anybody', 'beg', 'pardon', 'hear', 'color', 'chocchoc', 'last', 'night', 'nobody', 'jake', 'party', 'old', 'yellow', 'hair', 'mess', 'doesnt', 'mean', 'hafta', 'throw', 'stick', 'week', 'bowl', 'pea', 'car', 'paper', 'box', 'listen', 'quickly', 'saturday', 'crackle', 'man', 'wet', 'shower', 'talk', 'him', 'nosy', 'neighbor', 'then', 'u', 'packet', 'dry', 'before', 'tomato', 'watch', 'roll', 'round', 'snap', 'drive', 'off', 'few', 'minute', 'pop', 'shirt', 'remember', 'head', 'hat', 'im', 'sure', 'silly', 'crush', 'yoghurt', 'pot', 'little', 'shout', 'ninnin', 'pbbear', 'back', 'wave', 'choose', 'warm', 'cheeky', 'should', 'sit', 'highchair', 'first', 'help', 'tie', 'wodar', 'start', 'day', 'scarf', 'brown', 'ready', 'play', 'bring', 'photograph', 'them', 'woolly', 'most', 'together', 'quite', 'bear', 'strap', 'into', 'seat', 'waistcoat', 'collect', 'couldnt', 'bib', 'lace', 'hold', 'lastname', 'giddy', 'oop', 'abigail', 'rather', 'than', 'mud', 'dirty', 'tiny', 'hour', 'ive', 'take', 'stand', 'again', 'hello', 'once', 'work', 'grandma', 'granddad', 'weekend', 'pair', 'dimitra', 'poohbear', 'youll', 'probably', 'much', 'excite', 'shell', 'mind', 'inside', 'run', 'straight', 'upstair', 'food', 'thatll', 'downstair', 'or', 'fridge', 'tin', 'cupboard', 'scruffy', 'still', 'eat', 'chocolate', 'fall', 'tray', 'happen', 'must', 'lunch', 'full', 'fruitbowl', 'behind', 'whoop', 'read', 'storybook', 'gorgeou', 'theyll', 'johnlewi', 'ride', 'lift', 'noahsark', 'toy', 'department', 'restaurant', 'smart', 'coffee', 'sun', 'purdie', 'moon', 'outfit', 'haircut', 'actually', 'cut', 'stay', 'beautiful', 'hungry', 'careful', 'wanna', 'six', 'five', 'lose', 'might', 'twin', 'pig', 'ark', 'pull', 'didnt', 'feet', 'bet', 'purdy', 'aeroplane', 'jumper', 'hang', 'mr', 'noah', 'under', 'cushion', 'ear', 'worry', 'older', 'rebecca', 'christen', 'earlier', 'walk', 'near', 'vicar', 'becky', 'why', 'give', 'open', 'everyone', 'hide', 'own', 'want', 'lovely', 'poorly', 'suit', 'other', 'animal', 'bed', 'friend', 'teddybear', 'putt', 'toaster', 'tinypig', 'top', 'cotton', 'reel', 'sofa', 'shape', 'bright', 'birthday', 'either', 'hippopotamu', 'vest', 'hot', 'poppet', 'itll', 'burn', 'stair', 'sharp', 'needle', 'dad', 'okay', 'bash', 'spoon', 'slide', 'laugh', 'mouthful', 'finish', 'giraffe', 'marmalade', 'butter', 'gentle', 'toybox', 'really', 'mm', 'theyve', 'stripe', 'empty', 'picture', 'sort', 'towel', 'clothe', 'lion', 'belong', 'machine', 'climb', 'eleven', 'clear', 'while', 'left', 'bottom', 'spread', 'blow', 'bubble', 'teddy', 'horse', 'naughty', 'grass', 'edward', 'elephant', 'cheese', 'sandwich', 'dark', 'sky', 'dungaree', 'ask', 'tshirt', 'sew', 'onto', 'nearly', 'truck', 'vroom', 'even', 'airport', 'catch', 'colore', 'plate', 'button', 'pooh', 'wind', 'winniethepooh', 'lot', 'flower', 'pile', 'washingmachine', 'seven', 'slice', 'ramp', 'fur', 'eye', 'nose', 'turn', 'though', 'later', 'wont', 'properly', 'instead', 'candle', 'meow', 'patio', 'wipe', 'noisy', 'knee', 'sang', 'happybirthday', 'taste', 'fan', 'soft', 'bow', 'love', 'jump', 'april', 'ribbon', 'neck', 'molly', 'moment', 'ago', 'velvet', 'touch', 'share', 'piece', 'frighten', 'name', 'through', 'handle', 'bedroom', 'scream', 'point', 'light', 'high', 'hit', 'boat', 'tell', 'therere', 'pink', 'feed', 'sound', 'hard', 'longer', 'bath', 'enough', 'lady', 'sue', 'bless', 'wand', 'leave', 'step', 'spot', 'copy', 'dog', 'bark', 'maybe', 'clearly', 'pussy', 'block', 'view', 'heart', 'doggy', 'meat', 'crunchy', 'sailor', 'stripy', 'wonderful', 'middle', 'their', 'paddingtonbear', 'toward', 'clever', 'rattle', 'gosh', 'otherwise', 'loud', 'shake', 'gently', 'shouldnt', 'born', 'way', 'cot', 'until', 'christma', 'tree', 'werent', 'rough', 'table', 'strawberry', 'smell', 'tape', 'cool', 'wiggly', 'prop', 'straw', 'cloth', 'sticky', 'needta', 'tonight', 'without', 'program', 'pippin', 'visit', 'geese', 'pussycat', 'rug', 'next', 'windy', 'soap', 'whistle', 'youd', 'used', 'paw', 'meal', 'peace', 'both', 'wall', 'carry', 'special', 'far', 'quack', 'float', 'past', 'stop', 'beaker', 'mug', 'funny', 'early', 'pyjama', 'saucer', 'half', 'puppy', 'letter', 'window', 'any', 'post', 'hurt', 'anythe', 'pass', 'hasta', 'pant', 'ring', 'bell', 'away', 'card', 'thing', 'postbox', 'stir', 'alway', 'nicer', 'bird', 'thirsty', 'bare', 'binbag', 'people', 'house', 'monday', 'dustbin', 'rubbish', 'bin', 'dure', 'bag', 'playgroup', 'exactly', 'same', 'wheel', 'wiper', 'swishswishswish', 'cornflake', 'verse', 'horn', 'boo', 'girl', 'disappoint', 'men', 'side', 'story', 'mouse', 'blossom', 'ship', 'dance', 'jam', 'train', 'snow', 'mustnt', 'yourself', 'mention', 'glove', 'tigger', 'cold', 'cloudy', 'keep', 'plum', 'fly', 'march', 'lie', 'kitchen', 'cherry', 'bathroom', 'surprise', 'pretty', 'scooter', 'break', 'live', 'road', 'pansy', 'goodnes', 'lotsof', 'third', 'crunch', 'rabbit', 'magician', 'linda', 'alice', 'woof', 'piglet', 'purple', 'spill', 'dobbin', 'low', 'noonoo', 'mend', 'teapot', 'sing', 'crumb', 'busy', 'sellotape', 'poo', 'snipsnip', 'tickle', 'scissor', 'close', 'scratch', 'toenail', 'push', 'battery', 'cough', 'fish', 'cuddle', 'finger', 'lick', 'cake', 'may', 'telephone', 'piggy', 'print', 'till', 'tomorrow', 'chew', 'money', 'feel', 'pond', 'quackquack', 'notice', 'tummy', 'split', 'absolutely', 'nothe', 'apart', 'film', 'undress', 'sorry', 'pretend', 'garden', 'unclebrian', 'bang', 'hammer', 'melt', 'badge', 'year', 'cook', 'bandage', 'arm', 'oink', 'egg', 'fishes', 'dandelion', 'popper', 'curtain', 'zip', 'snip', 'never', 'hell', 'soon', 'whatre', 'frog', 'peel', 'small', 'rest', 'snack', 'd', 'cardigan', 'tip', 'buy', 'square', 'bead', 'sleeve', 'reach', 'clap', 'whilst', 'polish', 'trailer', 'jar', 'backward', 'oughta', 'soak', 'nine', 'ten', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty', 'thirty', 'windmill', 'wooden', 'microwave', 'heat', 'fit', 'tractor', 'mix', 'oldmacdonald', 'cab', 'teletubby', 'ahhah', 'quick', 'whale', 'thick', 'tight', 'easter', 'lid', 'net', 'number', 'leg', 'enjoy', 'between', 'hook', 'chimney', 'shut', 'load', 'ugh', 'farmer', 'eggbox', 'dadda', 'long', 'cover', 'squeak', 'itself', 'crispy', 'skirt', 'cow', 'sheep', 'underneath', 'younger', 'job', 'real', 'scrape', 'june', 'allow', 'everyday', 'clip', 'promise', 'theyd', 'smash', 'fasten', 'wouldnt', 'farm', 'by', 'everythe', 'treat', 'case', 'hedgehog', 'wallpaper', 'wallet', 'fun', 'playdoh', 'afterward', 'different', 'type', 'mine', 'driver', 'plain', 'follow', 'separate', 'hole', 'helmet', 'bye', 'sneak', 'use', 'part', 'wait', 'digger', 'press', 'helicopter', 'undo', 'manage', 'policeman', 'police', 'teaspoon', 'breakdown', 'prefer', 'traffic', 'cone', 'sign', 'ouch', 'mini', 'lunchtime', 'music', 'forget', 'mixture', 'rider', 'sometime', 'useta', 'mum', 'helpful', 'fireguard', 'huge', 'build', 'sposta', 'turtle', 'sweet', 'friday', 'pajama', 'along', 'somewhere', 'key', 'race', 'fetch', 'isobel', 'bethany', 'favorite', 'crash', 'room', 'forest', 'damage', 'mint', 'shed', 'hm', 'pattern', 'raspberry', 'draw', 'lime', 'leaf', 'sweety', 'gas', 'playdough', 'shine', 'rollingpin', 'plastic', 'cutter', 'quietly', 'wonder', 'trip', 'bunch', 'bowwow', 'gentleman', 'trim', 'petal', 'nail', 'ginger', 'bigger', 'fact', 'firemansam', 'bar', 'paint', 'dough', 'pitterpatter', 'rain', 'sea', 'swim', 'melon', 'tut', 'swan', 'beak', 'michael', 'dawn', 'wheelbarrow', 'hadta', 'price', 'shh', 'chain', 'rope', 'pus', 'miss', 'grow', 'tall', 'each', 'hill', 'august', 'second', 'pram', 'slip', 'summer', 'flood', 'chop', 'mummyll', 'ho', 'hug', 'fill', 'smile', 'vacuum', 'cleaner', 'jigsaw', 'puzzle', 'tom', 'flip', 'whoosh', 'shoelace', 'goodbye', 'slot', 'save', 'crisp', 'washingup', 'foot', 'strong', 'rude', 'nest', 'excuse', 'peg', 'circle', 'york', 'magic', 'word', 'board', 'moo', 'lamb', 'bicycle', 'flat', 'hop', 'wool', 'chick', 'wellington', 'neednt', 'jacket', 'temper', 'video', 'pushchair', 'choo', 'boot', 'happy', 'move', 'carriage', 'doubt', 'um', 'arrive', 'saw', 'tear', 'swallow', 'hen', 'lay', 'amount', 'rubber', 'short', 'tune', 'wherea', 'possible', 'country', 'tail', 'curly', 'switch', 'ssh', 'click', 'snout', 'ladder', 'likely', 'upset', 'harold', 'haroldthehelicopter', 'everything', 'terrible', 'storm', 'pine', 'fire', 'medicine', 'henry', 'young', 'plant', 'flash', 'bucket', 'air', 'siren', 'sail', 'treasure', 'sillybilly', 'able', 'wire', 'television', 'propeller', 'trunk', 'chicken', 'bake', 'fancy', 'discover', 'wherere', 'salad', 'choc', 'express', 'whatever', 'afraid', 'frame', 'deep', 'lucky', 'alone', 'bridge', 'brick', 'stack', 'tunnel', 'track', 'passenger', 'nightnight', 'end', 'guard', 'altogether', 'neigh', 'steady', 'fresh', 'crusty', 'dinner', 'teletubbie', 'kick', 'steam', 'seek', 'smily', 'bite', 'wish', 'smack', 'n', 'armchair', 'lotion', 'change', 'himself', 'andy', 'worse', 'bush', 'lisa', 'mhm', 'hey', 'newspaper', 'tanker', 'ceil', 'sad', 'cry', 'purpose', 'knife', 'large', 'twice', 'uh', 'hope', 'check', 'unhappy', 'kitkat', 'hardly', 'stroke', 'surround', 'star', 'fat', 'controller', 'carrot', 'sandal', 'powder', 'squeeze', 'scrub', 'squirt', 'amuse', 'myself', 'lorry', 'miserable', 'lively', 'computer', 'store', 'unplug', 'life', 'kangaroo', 'centre', 'smaller', 'butterfly', 'market', 'sprinkle', 'smelly', 'fast', 'seem', 'cheep', 'tweet', 'state', 'wee', 'pavement', 'tiddle', 'song', 'skin', 'pack', 'land', 'muddle', 'receipt', 'acros', 'sand', 'thumb', 'sunhat', 'line', 'hairbrush', 'landrover', 'bristle', 'roof', 'hadnt', 'wander', 'park', 'stiff', 'whereve', 'sunglass', 'tomatoe', 'further', 'bench', 'anywhere', 'comb', 'trap', 'fine', 'nappie', 'true', 'giggle', 'difference', 'builder', 'skip', 'broom', 'carefully', 'sooner', 'rescue', 'phone', 'sip', 'splash', 'paddy', 'suck', 'spaghetti', 'bolognese', 'gordon', 'normally', 'lean', 'forward', 'gather', 'character', 'cloud', 'everywhere', 'spend', 'sunday', 'sill', 'peep', 'punch', 'often', 'obviously', 'hanger', 'flatten', 'clue', 'supermarket', 'cord', 'involve', 'funnily', 'rub', 'blind', 'couple', 'cricket', 'grandad', 'shoot', 'trouble', 'sneeze', 'ohgosh', 'lap', 'chat', 'begin', 'anyway', 'baa', 'wrap', 'uhoh', 'crayon', 'tap', 'send', 'shoo', 'barn', 'join', 'collar', 'trolley', 'duckling', 'mother', 'brian', 'nono', 'lower', 'rip', 'lip', 'guitar', 'disc', 'glad', 'unwrap', 'kind', 'blouse', 'f', 'rinse', 'pillow', 'musical', 'instrument', 'mark', 'specially', 'cross', 'edge', 'since', 'cereal', 'anymore', 'jo', 'blanket', 'doctor', 'underpant', 'double', 'whoopsadear', 'rack', 'radiator', 'fireengine', 'pepper', 'cheepcheep', 'jug', 'chip', 'definitely', 'pencil', 'psh', 'duster', 'pinch', 'fed', 'mat', 'body', 'haha', 'envelope', 'tease', 'whisker', 'jolly', 'fluffy', 'auntie', 'mister', 'macdonald', 'realize', 'field', 'goodnight', 'happychristma', 'tighten', 'spanner', 'toolbox', 'unles', 'bike', 'sponge', 'imagine', 'bedtime', 'lego', 'win', 'match', 'flag', 'cycle', 'jaffacake', 'stone', 'gravel', 'foil', 'voicebox', 'b', 'voice', 'blackcurrant', 'nursery', 'possibly', 'themselve', 'teatime', 'brighten', 'action', 'obsess', 'pasta', 'seal', 'energy', 'id', 'idea', 'recognize', 'eh', 'silver', 'shiny', 'already', 'xylophone', 'lazy', 'best', 'sunny', 'usual', 'polo', 'sandpit', 'drum', 'dare', 'mistake', 'question', 'pocket', 'lock', 'every', 'mash', 'ink', 'leak', 'mice', 'bank', 'tidy', 'tubby', 'wink', 'mealtime', 'teethe', 'bill', 'sweep', 'smooth', 'surface', 'stamp', 'late', 'iron', 'whoever', 'main', 'ruth', 'sweeper', 'hed', 'wrapped', 'disappear', 'jean', 'seriously', 'picnic', 'peepo', 'wax', 'rose', 'tread', 'america', 'least', 'stockport', 'drag', 'carpet', 'steer', 'flavore', 'ledge', 'woosh', 'socket', 'school', 'mothercare', 'expensive', 'fork', 'muddy', 'learn', 'tablet', 'dissolve', 'tag', 'sweetcorn', 'impress', 'sausage', 'sticker', 'aerial', 'easteregg', 'gardener', 'radio', 'sudden', 'label', 'band', 'margarine', 'cute', 'bend', 'accident', 'above', 'brightly', 'mirror', 'carrier', 'french', 'whole', 'care', 'settee', 'normal', 'fold', 't', 'waste', 'fascinate', 'especially', 'comfortable', 'c', 'shock', 'bloom', 'worth', 'cement', 'mixer', 'chase', 'decide', 'understand', 'fair', 'rubyre', 'bobthebuilder', 'sugar', 'suggest', 'didsbury', 'guess', 'wed', 'death', 'salt', 'vinegar', 'set', 'holiday', 'suntan', 'cream', 'onion', 'tricycle', 'rush', 'pedal', 'occasionally', 'wrist', 'ordinary', 'feather', 'stalk', 'shade', 'malteser', 'lampshade', 'curry', 'bad', 'dirt', 'tube', 'measure', 'rainbow', 'add', 'flowerpot', 'hotter', 'several', 'nicely', 'sell', 'rachel', 'village', 'person', 'awful', 'such', 'nothing', 'safe', 'messy', 'ladybird', 'liedown', 'whether', 'bob', 'space', 'tower', 'roar', 'dust', 'tooth', 'drip', 'splish', 'whatve', 'problem', 'palm', 'poke', 'blame', 'purr', 'rumble', 'wrong', 'temperature', 'oil', 'upside', 'complain', 'completely', 'free', 'model', 'aunty', 'swing', 'answer', 'pity', 'tesco', 'danger', 'steven', 'bean', 'magazine', 'pud', 'daniel', 'sigh', 'tiger', 'manchester', 'worktop', 'zoo', 'drain', 'cockadoodledoo', 'everybody', 'attack', 'headache', 'dolly', 'control', 'fireplace', 'tuesday', 'fault', 'beanbag', 'sleepy', 'strange', 'admit', 'cooker', 'within', 'dine', 'neither', 'nor', 'sixty', 'teatowel', 'mood', 'dish', 'rock', 'postcard', 'nasty', 'sunshine', 'dial', 'children', 'shush', 'rise', 'fabric', 'conditioner', 'crane', 'string', 'theater', 'winter', 'santa', 'letterbox', 'cause', 'mitten', 'dead', 'pebble', 'apron', 'pad', 'squeaky', 'great', 'doll', 'smudge', 'liquid', 'bathe', 'surgery', 'oopsadear', 'die', 'vase', 'shelf', 'plaster', 'office', 'sack', 'dustpan', 'recorder', 'shame', 'grind', 'suppose', 'wake', 'dream', 'dig', 'tablecloth', 'game', 'ow', 'icecream', 'monkey', 'wood', 'squashy', 'gum', 'ha', 'whee', 'protect', 'aid', 'cancer', 'bore', 'donkey', 'pitter', 'patter', 'joe', 'umbrella', 'raise', 'puddle', 'sore', 'nappy', 'thursday', 'paddle', 'pool', 'pan', 'funnel', 'pastry', 'bruise', 'rash', 'easily', 'joke', 'dot', 'noddy', 'plug', 'manner', 'rice', 'order', 'railway', 'branch', 'teach', 'blackberry', 'tinker', 'peter', 'paul', 'kitten', 'age', 'rail', 'caterpillar', 'felix', 'spit', 'windowcleaner', 'isabel', 'chest', 'month', 'chin', 'tub', 'harm', 'toddler', 'group', 'dotty', 'spotty', 'freddy', 'lead', 'speak', 'sweatshirt', 'toothbrush', 'message', 'friendly', 'grandpa', 'quicker', 'sonia', 'macclesfield', 'swish', 'toothpaste', 'furniture', 'les', 'wendyhouse', 'holly', 'spade', 'squash', 'recently', 'proud', 'heh', 'grubby', 'sheet', 'whichever', 'pleasant', 'ham', 'greet', 'stage', 'jill', 'smoke', 'salmon', 'auntylinda', 'moth', 'tram', 'plane', 'sniff', 'wing', 'flutter', 'fresher', 'something', 'nurse', 'bouncy', 'yawn', 'clock', 'lit', 'oven', 'bathtime', 'fairy', 'potty', 'spin', 'certain', 'page', 'prepare', 'unusual', 'yumyum', 'phew', 'daisy', 'baker', 'gift', 'voucher', 'eventually', 'lamp', 'pip', 'seed', 'daffodil', 'smelt', 'tumble', 'spout', 'octopu', 'oval', 'ben', 'matthew', 'shoulder', 'platform', 'tortoise', 'collapse', 'weight', 'soil', 'trowel', 'louder', 'almost', 'believe', 'flatter', 'sharon', 'rattly', 'eggcup', 'gold', 'preciou', 'pilot', 'dizzy', 'posh', 'cube', 'sink', 'size', 'slightly', 'larger', 'proper', 'nought', 'lulu', 'pat', 'present', 'damp', 'camera', 'straighten', 'settle', 'safely', 'segment', 'max', 'tangerine', 'stool', 'lighter', 'bonnet', 'auntymabel', 'family', 'february', 'cardboard', 'dresser', 'stencil', 'quarter', 'dump', 'fuss', 'boss', 'core', 'scarecrow', 'charity', 'explain', 'poppy', 'none', 'dip', 'buzz', 'hurry', 'charlotte', 'alphabet', 'furry', 'dingalingale', 'whizz', 'alarm', 'ever', 'beeba', 'sauce', 'cheesy', 'whatsit', 'o', 'abacu', 'file', 'tommy', 'motorway', 'ta', 'saintgabriel', 'g', 'h', 'j', 'k', 'l', 'service', 'station', 'm', 'p', 'q', 'r', '', 'w', 'x', 'y', 'z', 'leed', 'journey', 'snail', 'queen', 'speed', 'awake', 'beebah', 'morning', 'important', 'clay', 'okeydokey', 'compare', 'weather', 'october', 'december', 'concern', 'wriggle', 'although', 'chomp', 'fee', 'handprint', 'path', 'cheer', 'ticktock', 'scoop', 'rake', 'thicker', 'interest', 'dumper', 'tissue', 'barrow', 'coathanger', 'nearer', 'firemen', 'bendy', 'heaven', 'huh', 'lawnmower', 'against', 'weed', 'metal', 'grumpy', 'complete', 'ice', 'wheelsonthebu', 'kite', 'boulder', 'reverse', 'talcum', 'cable', 'log', 'lemonade', 'mushroom', 'auntiemabel', 'gate', 'heel', 'dotdot', 'wherever', 'scribble', 'ourselve', 'dairylea', 'deliciou', 'sainsbury', 'bother', 'herb', 'sister', 'violin', 'tick', 'tock', 'burst', 'wasp', 'hospital', 'mightnt', 'bee', 'bone', 'strainer', 'tow', 'yo', 'bounce', 'finally', 'refuse', 'beach', 'september', 'also', 'darker', 'crab', 'brave', 'grunt', 'whove', 'peach', 'balance', 'cheek', 'diamond', 'reception', 'fantastic', 'rang', 'purpley', 'meet', 'sarah', 'sunglas', 'include', 'ambulance', 'blonde', 'screw', 'teeshirt', 'yum', 'fluff', 'lily', 'tightly', 'grey', 'unload', 'conversation', 'girlfriend', 'lasagne', 'site', 'stain', 'liam', 'jessica', 'container', 'uniform', 'wedge', 'jane', 'georgia', 'arrange', 'unclestuart', 'uncle', 'slippery', 'tele', 'mantelpiece', 'beehive', 'rhyme', 'marry', 'fifty', 'chance', 'dolphin', 'seventy', 'peggy', 'roundabout', 'wafer', 'panda', 'wouldve', 'offer', 'manager', 'plan', 'tend', 'cutlery', 'horrible', 'parrot', 'seriou', 'isabelle', 'mop', 'coaster', 'shovel', 'pay', 'ribena', 'dive', 'buttercup', 'badly', 'compost', 'choice', 'loaf', 'precisely', 'chemist', 'spray', 'hood', 'penguin', 'trainer', 'fireman', 'hippo', 'sultana', 'currant', 'crocodile', 'tuck', 'opposite', 'certainly', 'compartment', 'extra', 'smarty', 'puff', 'anyone', 'travele', 'roller', 'stem', 'lavender', 'organize', 'amongst', 'wardrobe', 'bobbin', 'chuff', 'ahead', 'alive', 'traffordcentre', 'closer', 'earth', 'jungle', 'address', 'fence', 'flap', 'unfortunately', 'lesson', 'twinkle', 'raisin', 'toilet', 'eighteenth', 'potato', 'reason', 'calm', 'ping', 'supper', 'hotel', 'rocket', 'class', 'child', 'university', 'pizza', 'brother', 'triangle', 'useful', 'therell', 'wife', 'feature', 'julian', 'reflection', 'flask', 'loudly', 'slowly', 'beat', 'tatty', 'polite', 'patch', 'rod', 'extension', 'david', 'mrsnoah', 'waterwheel', 'goldfish', 'footprint', 'microphone', 'nowhere', 'whoo', 'attach', 'tasty', 'turkey', 'loop', 'cheat', 'zebra', 'nectarine', 'satsuma', 'term', 'bbc', 'vegetable', 'handbag', 'lad', 'dull', 'pie', 'remind', 'crust', 'stretch', 'teacher', 'chug', 'height', 'tongue', 'imitate', 'disturb', 'custard', 'cheque', 'fairly', 'hoover', 'lollipop', 'fizzy', 'annoy', 'king', 'brake', 'dalmatian', 'carton', 'hundr', 'sieve', 'leap', 'china', 'cabinet', 'piano', 'stuff', 'single', 'waterproof', 'ding', 'sour', 'soggy', 'luckily', 'expect', 'suddenly', 'relax', 'however', 'buzzy', 'purse', 'muck', 'yuck', 'test', 'weasel', 'mantlepiece', 'father', 'doorbell', 'whenever', 'lump', 'whisk', 'tickly', 'pipe', 'bound', 'advertise', 'perfect', 'sick', 'smartie', 'everytime', 'weigh', 'scale', 'appreciate', 'pleasure', 'bertiethebu', 'pound', 'ounce', 'giggler', 'bras', 'decorate', 'wah', 'whoa', 'pony', 'heavier', 'flapjack', 'wide', 'shute', 'warmer', 'owner', 'oat', 'horror', 'porridge', 'walker', 'soup', 'equipment', 'shampoo', 'note', 'rid', 'course', 'become', 'wrapper', 'record', 'sam', 'tyre', 'cap', 'trot', 'ingredient', 'somehow', 'stall', 'golden', 'syrup', 'flavor', 'calpol', 'doughnut', 'factory', 'teabag', 'hay', 'throat', 'vehicle', 'coleslaw', 'tipper', 'excitement', 'gonna', 'luggage', 'spain', 'pit', 'sweetie', 'bunny', 'collection', 'fighter', 'hose', 'storage', 'city', 'healthy', 'runny', 'honey', 'sweaty', 'knive', 'unpack', 'return', 'borrow', 'cabbage', 'buffer', 'flame', 'deal', 'range', 'storytime', 'nuisance', 'seaside', 'scrap', 'refer', 'willie', 'hopefully', 'world', 'material', 'twirl', 'twist', 'roast', 'knot', 'newsagent', 'garage', 'practice', 'diddle', 'dumple', 'son', 'motorbike', 'bah', 'warn', 'aitchoo', 'bulldozer', 'blade', 'welcome', 'workmen', 'taxi', 'street', 'earring', 'apparently', 'submarine', 'pita', 'unlock', 'secure', 'fix', 'blackpool', 'pilchard', 'crack', 'didsburypark', 'jelly', 'juicy', 'welly', 'episode', 'shortbread', 'honestly', 'john', 'apricot', 'fox', 'stare', 'deserve', 'squirrel', 'vet', 'crowd', 'catalogue', 'bum', 'telly', 'crawl', 'enormou', 'appear', 'yummy', 'easy', 'deary', 'confuse', 'tot', 'happier', 'blood', 'date', 'castle', 'ripe', 'pale', 'july', 'itd', 'burglar', 'ninety', 'drawer', 'floppy', 'row', 'belly', 'magpie', 'barber', 'greenhouse', 'sooty', 'list', 'wine', 'paste', 'leonard', 'bobble', 'spare', 'plenty', 'bingbong', 'fight', 'tart', 'terribly', 'thin', 'injection', 'mainly', 'delicate', 'lolly', 'invitation', 'invite', 'stephen', 'dummy', 'insist', 'handy', 'library', 'practise', 'describe', 'freezer', 'charge', 'foam', 'club', 'disgust', 'tuna', 'pi', 'whereabout', 'tinky', 'winky', 'elaine', 'hedge', 'shear', 'uncledavid', 'tool', 'tank', 'fragile', 'master', 'ba', 'dame', 'lane', 'spring', 'lawn', 'edger', 'chunk', 'nip', 'junk', 'mail', 'passtheparcel', 'layer', 'sonya', 'stock', 'swap', 'butcher', 'creche', 'superb', 'paid', 'bury', 'area', 'grab', 'season', 'pumpkin', 'concentrate', 'jonathan', 'speckle', 'form', 'spencer', 'hairdresser', 'delivery', 'rolly', 'potatoe', 'adventure', 'soldier', 'cracker', 'cling', 'fatherchristma', 'auntiesharon', 'thomasthetank', 'bangadrumtime', 'autumn', 'seedling', 'footpath', 'sting', 'slow', 'dusty', 'elena', 'shy', 'dozen', 'mower', 'camp', 'super', 'higher', 'hosepipe', 'breath', 'brum', 'pingu', 'private', 'spoil', 'owl', 'christopher', 'cockerel', 'mould', 'playground', 'wibblewobble', 'untidy', 'pet', 'busines', 'peer', 'schoollane', 'heck', 'recycle', 'cottage', 'beautifully', 'spider', 'wobble', 'tellytubby', 'badger', 'calendar', 'thomashenry', 'purditer', 'seventh', 'reardon', 'tack', 'amber', 'agree', 'doodle', 'forty', 'signal', 'elbow', 'creep', 'george', 'jack', 'tubbie', 'solution', 'leaflet', 'surely', 'instruction', 'doctorharrison', 'pence', 'coin', 'motor', 'soapy', 'bulb', 'stable', 'penny', 'dangerou', 'electric', 'bluey', 'attention', 'daddyll', 'fizz', 'dentist', 'nugget', 'stitch', 'quaver', 'gap', 'sensible', 'mobile', 'eclipse', 'adam', 'claw', 'actual', 'streetname', 'perfectly', 'fingernail', 'serve', 'pin', 'particularly', 'cafe', 'trick', 'november', 'lauren', 'indee', 'loft', 'snake', 'nearest', 'mustve', 'bumpy', 'cheshire', 'mabel', 'corn', 'brigade', 'kathy', 'pate', 'company', 'ray', 'navy', 'munch', 'fred', 'caitlin', 'auntielinda', 'shopkeeper', 'rectangle', 'jenny', 'direction', 'odd', 'steve', 'cathy', 'lynne', 'marshmallow', 'hip', 'hooray', 'medal', 'luck', 'limousine', 'spoonful', 'knit', 'thread', 'dangle', 'pippo', 'prize', 'earlylearningcentre', 'suitable', 'parkin', 'jess', 'gobble', 'town', 'hall', 'bacon', 'stuart', 'accord', 'embarrass', 'bonfire', 'firework', 'magpy', 'scare', 'burnage', 'mask', 'slippy', 'norman', 'bungalow', 'spar', 'glitter', 'dib', 'dob', 'cheap', 'zero', 'millennium', 'indicator', 'helen', 'cattery', 'appointment', 'refresh', 'giant', 'missu', 'sparkly', 'joseph', 'ache', 'mad', 'gobbledygook', 'kneel', 'pump', 'nina', 'maker', 'pole', 'brand', 'arrow', 'fourth', 'gown', 'liz', 'sale', 'burger', 'pigeon', 'coke', 'chilly', 'marble', 'hiccup', 'clown', 'christmasday', 'cellotape', 'ratty', 'candy', 'milky', 'grandparent', 'margaret', 'jakejimmy', 'whyve', 'repair', 'husband', 'cousin', 'daughter', 'difficult', 'sir', 'unit', 'mousse', 'plough', 'bleed', 'elderly', 'excellent', 'postcode', 'safety', 'thirteenth', 'twelfth', 'marcu', 'em', 'monster', 'thebeehive', 'whisper', 'bud', 'suitcase', 'spatula', 'dishwasher', 'hummu', 'rachael', 'mcdonald', 'conservatory', 'robert', 'napkin', 'grip', 'ther', 'disco', 'headphone', 'breathe', 'travel', 'cocacola', 'student', 'necklace', 'holder', 'mucky', 'spell', 'de', 'counter', 'assistant', 'stronger', 'boiler', 'yard', 's', 'london', 'ignore', 'grannydryden', 'lynn', 'dribble', 'information', 'lonely', 'beatrixpotter', 'tale', 'jemimapuddleduck', 'force', 'jakekelly', 'common', 'magnet', 'flake', 'firm', 'ticket', 'oy', 'transporter', 'gallop', 'anna', 'steep', 'spa', 'hiss', 'beef', 'alison', 'jonathon', 'depend', 'greengrocer', 'sledge', 'barrier', 'parent', 'cadbury', 'gibraltar', 'secret', 'shelve', 'crown', 'daddyrod', 'scotland', 'tent', 'rein', 'slug', 'france', 'spanish', 'decoration', 'biro', 'insect', 'graciou', 'activity', 'curl', 'wagon', 'coal', 'laura', 'pox', 'policemen', 'bracelet', 'grandfather', 'dash', 'blackbird', 'peck', 'waiter', 'streamer', 'seagull', 'alligator', 'eighty', 'beer', 'auntieval', 'grate', 'alot', 'litter', 'dessert', 'attendant', 'shant', 'reverendtimm', 'dinosaur', 'level', 'loose', 'flour', 'snuffily', 'mile', 'particular', 'cart', 'inceywincey', 'customer', 'stupid', 'glue', 'tony', 'mass', 'glaze', 'reverandtim', 'milkshake', 'behave', 'bolt', 'granddadbealby', 'playtime', 'gingerbread', 'raw', 'littlebear', 'casserole', 'cancele', 'ricekrispie', 'whiska', 'strip', 'distance', 'postoffice', 'greendale', 'prickly', 'colander', 'lighthouse', 'krispy', 'chef', 'missusgoggin', 'halfway', 'crow', 'largest', 'dorothy', 'inch', 'freeze', 'paddock', 'conker', 'grater', 'kate', 'la', 'sud', 'visitor', 'auntiejanet', 'poop', 'electricity', 'joshua', 'belt', 'farty', 'eeyore', 'doug', 'shaky', 'peeweebear', 'snowy', 'wale', 'wendy', 'snowman', 'berry', 'mary', 'ruler', 'jackinthebox', 'puppet', 'messpot', 'drill', 'jingle', 'halloween', 'lofty', 'breadstick', 'milkman', 'nut', 'torch', 'fifth', 'frosty', 'pickle', 'rickkrispy', 'anchor', 'brr', 'baalamb', 'access', 'tough', 'wobbly', 'hare', 'crate', 'bun', 'nativity', 'scene', 'wise', 'beard', 'forklift', 'dougla', 'william', 'snotsnot', 'heatonmersey', 'tweeny', 'choir', 'timer', 'workbench', 'oxygen', 'caravan', 'extremely', 'petrol', 'harry', 'snowmen', 'thousand', 'bauble', 'prawn', 'dora', 'chinese', 'workshop', 'humptydumpty', 'hickorydickorydock', 'mince', 'sleigh', 'pee', 'toffee', 'aw', 'advent', 'breast', 'robin', 'witch', 'angel', 'reindeer', 'tinsel', 'travi', 'tartan', 'january', 'rainy', 'cola', 'river', 'spud', 'wolf', 'bella', 'sherry', 'eve', 'rudolph', 'fleece', 'millenium', 'merry', 'rewind', 'jinglebell', 'christmaseve', 'flick', 'grocer', 'complicate', 'tabard', 'depot', 'ruldolph', 'lantern', 'guide', 'raffle', 'wrench', 'alien', 'spaceship', 'spaceman', 'mistletoe', 'crankythecrane', 'tusk', 'grandmabealby', 'nanabealby', 'carol', 'detector', 'ostrich', 'missushubbard', 'local', 'misshubbard', 'bannister', 'shepherd', 'tim', 'tsk', 'bo', 'biff', 'earr', 'jesu', 'bossy', 'link', 'canister', 'woody', 'milo', 'sistereileen', 'dan', 'snug', 'sharpen', 'abracadabra', 'prick', 'louise', 'jewelery', 'canada', 'dicky', 'cocktail', 'spicy', 'diet', 'dougal', 'purd', 'spice', 'nephew', 'betty', 'glance', 'owe', 'mischief', 'nick', 'donald', 'wriggly', 'brilliant', 'hurrah', 'auntyfrank', 'hopscotch', 'snowball', 'chief', 'attic', 'exercise', 'sprout', 'scary', 'auntiefrank', 'boop', 'keeper', 'icy', 'gem', 'squish', 'tug', 'cranberry', 'emergency', 'tweenie', 'maypole', 'bodger', 'petsmart', 'scarborough', 'grandadbealby', 'pave', 'lake', 'screwdriver', 'caution', 'leather', 'player', 'woman', 'crunchie', 'cost', 'piccadilly', 'report', 'worm', 'freddie', 'preston', 'underground', 'grandadbeilbie', 'oatmeal', 'grin', 'bug', 'steal', 'beefburger', 'sugary', 'hero', 'shark', 'eddie', 'fuzzy', 'forever', 'boom', 'hula', 'hoop', 'wheelie', 'gingell', 'royalmail', 'strand', 'cash', 'neena', 'kill', 'kanga', 'alex', 'earn', 'sunflower', 'trace', 'firefighter', 'morri', 'bumpity', 'cuckoo', 'slithery', 'sideway', 'judy', 'jellytot', 'cbbc', 'pirate', 'woolworth', 'pod', 'glossop', 'gingerbattersby', 'burnagestation', 'scania', 'tnt', 'jeannine', 'runaway', 'scone', 'pancake', 'credit', 'oldbear', 'mole', 'decker', 'huggle', 'neenaw', 'buzzlightyear', 'shopman', 'camel', 'missmoppet', 'liquorice', 'dragon', 'thistle', 'knob', 'misterpebbleman', 'jamie', 'daft', 'missusplatford', 'babyroo', 'roo', 'christopherrobin', 'major', 'dediddleydum', 'midget', 'gun', 'merseyvale', 'duper', 'walkietalkie', 'cork', 'arrest', 'pooey', 'army', 'flos', 'handcuff', 'missusplattford', 'zoe', 'mrsplattford', 'tayberry', 'fudge', 'axe', 'lottery', 'hate', 'kiera', 'anthony', 'jail', 'sparkler', 'robber', 'ghost', 'antony', 'luke', 'vitamin', 'gravy', 'cellar', 'samara', 'sergeant', 'platford', 'grabber', 'ashworth', 'superman', 'barbeque', 'grettal', 'glasgow', 'tong', 'buse', 'neenah', 'dum', 'olden', 'nathan', 'nanna', 'orangutan', 'grit', 'mrswilson', 'lucozade', 'fido', 'roadblock', 'acid', 'throne', 'ayisha', 'monstersinc', 'freshener', 'woah', 'trampy'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code for the word \"biscuit\" is 125\n"
     ]
    }
   ],
   "source": [
    "# We associate a numerical index to each word, which we later use to locate the word in the co-occurrence matrix\n",
    "w2i = {w: i for i, w in enumerate(targets)}\n",
    "i2w = {i: w for i, w in enumerate(targets)}\n",
    "\n",
    "#Example:\n",
    "print(\"The code for the word \\\"biscuit\\\" is {}\".format(w2i[\"biscuit\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# This function is used to build the co-occurrence matrix\n",
    "def calculate_cooccurrences(tokenized, vocabulary_size, window):\n",
    "    matrix = np.zeros([vocabulary_size,vocabulary_size]) \n",
    "    for sentence in tokenized:\n",
    "        for position,word in enumerate(sentence):                \n",
    "            for j in range(max(position-window,0),min(position+window+1,len(sentence))):\n",
    "                context=sentence[j]\n",
    "                if j!=position and word in targets and context in targets: \n",
    "                    matrix[w2i[word]][w2i[context]]+=1\n",
    "    return matrix\n",
    "\n",
    "\n",
    "#This function will give us the co-occurrence between two words\n",
    "def get_cooccurrence(word1, word2):\n",
    "    return co_occurrence_counts[w2i[word1]][w2i[word2]]\n",
    "\n",
    "#We now compute the co-occurrences in our tokenized text\n",
    "co_occurrence_counts=calculate_cooccurrences(tokenized, vocabulary_size, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "#Let's have a look at some co-occurrences:\n",
    "print(get_cooccurrence(\"glass\", \"milk\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
